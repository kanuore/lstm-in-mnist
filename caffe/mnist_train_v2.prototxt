# Enter your network definition here.
# Use Shift+Enter to update the visualization.
name: "LeNet"
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "/media/lbk/ubuntu file/dataset/mnist/caffe/mnist_train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}

# 将data转换为 [T,Batch, H]
# 将batch改成1
layer {
  name: "reshape_data"
  type: "Reshape"
  bottom: "data"
  top: "reshape_data"
  reshape_param {
    shape {
      dim:28 
        dim:128
        dim:28
    }
  }
}

# 提供连续标志，证明连续一张像素行
layer {
  name: "cont"
  type: "HDF5Data"
  top: "cont"
  hdf5_data_param {
    source: "/home/lbk/ocr/LSTM/caffe/lstm_conv_h5.txt" 
    batch_size: 128
  }
}



#将 cont 转换为 [T, batch]
layer {
  name: "reshape_cont"
  type: "Reshape"
  bottom: "cont"
  top: "reshape_cont"
  reshape_param {
    shape { 
      dim:28 
      dim:128
    }
  }
}

layer {
  name: "lstm"
  type: "LSTM"
  bottom: "reshape_data"
  bottom: "reshape_cont"
  top: "lstm"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  
  recurrent_param {
    num_output: 128 # 这里果然可以随便设置的，应该是参数w的大小
    clipping_threshold: 0.1
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
#输出为28个时间步的 output [T, batch, 10] 只使用第28个时间步的值 output2
layer {
  name: "slice"
  type: "Slice"
  bottom: "lstm"
  top: "output1"
  top: "output2"
  slice_param {
    axis: 0
    slice_point: 27
  }
}

#output1 一直输出影响观察，这里随便加的一层，没有作用
layer {
  name: "reduction"
  type: "Reduction"
  bottom: "output1"
  top: "output11"
  reduction_param {
    axis: 0
  }
}


# 将data转换为 [Batch,T, H]
layer {
  name: "reshape_2_fc"
  type: "Reshape"
  bottom: "output2"
  top: "reshape_2_fc"
  reshape_param {
    shape {
      dim:128 
      dim:-1
    }
  }
}


layer {
  name: "fc"
  type: "InnerProduct"
  bottom: "reshape_2_fc"
  top: "fc"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}

layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc"
  bottom: "label"
  top: "loss"
}
