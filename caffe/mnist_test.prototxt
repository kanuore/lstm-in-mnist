name: "LeNet"
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param { shape: { dim: 1 dim: 1 dim: 28 dim: 28 } }
}

# 将data[N,C,W,H]转换为 [T,Batch, H]
# 将batch改成1
layer {
    name: "trans_data"
    type: "TensorTranspose"
    bottom: "data"
    top: "trans_data"
    tensor_transpose_param { 
      order: 2 
      order: 0 
      order: 3 
      order: 1
    }
}
layer {
  name: "reshape_data"
  type: "Reshape"
  bottom: "trans_data"
  top: "reshape_data"
  reshape_param {
    shape {
      dim:28 
      dim:-1
      dim:28
    }
  }
}

# 提供连续标志，证明连续一张像素行
layer {
  name: "cont"
  type: "HDF5Data"
  top: "cont"
  hdf5_data_param {
    source: "/home/lbk/ocr/LSTM/caffe/lstm_conv_h5.txt" 
    batch_size: 1
  }
}
#将 cont 转换为 [T, batch]
layer {
    name: "trans_cont"
    type: "TensorTranspose"
    bottom: "cont"
    top: "trans_cont"
    tensor_transpose_param { 
      order: 1 
      order: 0 
    }
}

layer {
  name: "lstm"
  type: "LSTM"
  bottom: "reshape_data"
  bottom: "trans_cont"
  top: "lstm"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  
  recurrent_param {
    num_output: 128 # 这里果然可以随便设置的，应该是参数w的大小
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
#输出为28个时间步的 output [T, batch, 10] 只使用第28个时间步的值 output2
layer {
  name: "slice"
  type: "Slice"
  bottom: "lstm"
  top: "output1"
  top: "output2"
  slice_param {
    axis: 0
    slice_point: 27
  }
}

#output1 一直输出影响观察，这里随便加的一层，没有作用
layer {
  name: "reduction"
  type: "Reduction"
  bottom: "output1"
  top: "output11"
  reduction_param {
    axis: 0
  }
}

#将 cont 转换为 [batch,T]
layer {
    name: "trans_out"
    type: "TensorTranspose"
    bottom: "output2"
    top: "trans_out"
    tensor_transpose_param { 
      order: 1
      order: 0
      order: 2
    }
}

layer {
  name: "reshape_out"
  type: "Reshape"
  bottom: "trans_out"
  top: "reshape_out"
  reshape_param {
    shape {
      dim:-1 
      dim:1
      dim:1
      dim:128
    }
  }
}

layer {
  name: "fc"
  type: "InnerProduct"
  bottom: "reshape_out"
  top: "fc"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}

layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc"
  top: "prob"
}